{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practical No. 2"
      ],
      "metadata": {
        "id": "R3N6qBCfl5N_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name: Ashish Gupta.**\n",
        "\n",
        "**Roll no: 16**\n",
        "\n",
        "**Class: D16AD**"
      ],
      "metadata": {
        "id": "blzifOE4jR0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aim:** To collect Data from Social Media Platform using suitable Web Scraping Tools."
      ],
      "metadata": {
        "id": "FQvlvaa5jyFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method Used for scrapping:**\n",
        "1. Generate a Personal Access Token:\n",
        "* Go to your GitHub account settings.\n",
        "* Navigate to \"Developer settings\" -> \"Personal access tokens.\"\n",
        "* Click on \"Generate token\" and follow the instructions.\n",
        "* Make sure to grant the necessary permissions for the token.\n",
        "\n",
        "2. Write python script for web scrapping and put generated token in headers and provide github username whose data you want to scrap."
      ],
      "metadata": {
        "id": "ahD0sNPyl-0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_user_repositories(username):\n",
        "    api_url = f'https://api.github.com/users/{username}/repos'\n",
        "\n",
        "    headers = {'Authorization': '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'}\n",
        "\n",
        "    response = requests.get(api_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        repos = response.json()\n",
        "        return repos\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "3OF7DzM3X1vU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "username = 'ashishgupta'\n",
        "user_repos = get_user_repositories(username)\n",
        "\n",
        "if user_repos:\n",
        "    print(f\"Repositories for {username}:\")\n",
        "    for repo in user_repos:\n",
        "        print(f\"- {repo['name']}\")\n",
        "        print(f\"  Description: {repo['description']}\")\n",
        "        print(f\"  Stars: {repo['stargazers_count']}\")\n",
        "        print(f\"  Forks: {repo['forks_count']}\")\n",
        "        print(\"\\n\")\n",
        "else:\n",
        "    print(\"Failed to fetch user repositories.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlEmb_euKNTt",
        "outputId": "042cd651-747e-43f1-9ebc-b02182f0d18e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repositories for ashishgupta:\n",
            "- GreenR-visual-plant-necrosis-analysis-fork\n",
            "  Description: Disease detection in plant images. Weekend hackathon event at Columbus Ohio.\n",
            "  Stars: 0\n",
            "  Forks: 0\n",
            "\n",
            "\n",
            "- MRI-QA\n",
            "  Description: The assessment of quality of MRI is in important precursor to ameliorating biases in subsequent data analysis and precluding erroneous acquisitions. Since manual visual inspection is impractical for large volumes of data, as well as being subjective in nature, it is very useful to automate the task of image quality assessment (IQA). There is existing research on IQA, that typically utilize hand-crafted visual features in conjunction with machine learning algorithms. However, these techniques have been made obsolete in many research fields by much more powerful and expressive deep learning based models. We introduce a model that uses a Convolutional Neural Network for  feature extraction from 3D volumes of MRI data of a subject and a Fully Connected Network for classification of the quality of the MRI. This model is trained on a multi-site freely available dataset, called ABIDE 1, used in study of Autism. By utilizing two of the seventeen sites as hold-out data, we demonstrate that our model achieves state-of-art performance on unseen data from novel sites. Furthermore, we evaluate our trained model on a MRI dataset from TCIA, used in study of Glioblastoma, to demonstrate the ability of our model to effectively adapt to different types of neuro-imaging data.\n",
            "  Stars: 0\n",
            "  Forks: 0\n",
            "\n",
            "\n",
            "- srtm-terrain\n",
            "  Description: Python opengl srtm terrain\n",
            "  Stars: 0\n",
            "  Forks: 0\n",
            "\n",
            "\n",
            "- Thesis\n",
            "  Description: PhD Thesis\n",
            "  Stars: 0\n",
            "  Forks: 0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FqKTDIV5-qBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}